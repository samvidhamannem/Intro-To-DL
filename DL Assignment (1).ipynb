{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Mean Squared Error- It is a measure of how close the fitted line is to the data points since it represents the difference between the original and predicted values .It has units squared of the plotted measure on vertical axis. \n",
    "Root Mean squared errror-It is the error rate by the square root of MSE. It is easily interpretable since it has same units as the quantity plotted on the horizontal axis.RMSE can be directly interpreted in terms of measurement units, and hence it is a better measure of fit than a correlation coefficient.\n",
    "RMSE is more useful when lower residual values are preferred.MSE is highly biased for higher values.\n",
    "MSE penalizes large differences between the predicted and expected results as the penalty is not proportional to the error but to the square of the error.\n",
    "\n",
    "2.b) Adding more features to the dataset increases the amount of information you can extract from the dataset.So, we can use smaller datasets and we can overcome problem of overfitting.\n",
    "\n",
    "3)a)For the given model the training loss is decreasing due to overfitting. This can be caused by over training the data. \n",
    "Reducing the learning rate would be an optimal solution for this.\n",
    "Suggestion to rectify this- \n",
    "Preprocessing the data- Normalization and standardization\n",
    "Reduce the number of layers if the model is too complex\n",
    "Reduce the learning rate\n",
    "\n",
    "4)Ture\n",
    "true\n",
    "\n",
    "5)True\n",
    "False\n",
    "\n",
    "6)c\n",
    "\n",
    "9)If we initialize parameters with zeros when training a logistic regression model then after back propogation each \n",
    "of them will have same weights. \n",
    "Back propagation- Propagating the total loss back into the network.\n",
    "So if the weights are zero. We cannot calculate the loss for each node.It updates the weights to minimize the loss. So,\n",
    "if we are considering the initial weights as zeroes we have nothing to calculate.\n",
    "\n",
    "10)Cost(f(x),y) is 0 when y=1 and f(x)=1\n",
    "It will not work in actual implementation.Because log 0 is undefined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y = np.arange(-20, 20.1, 0.1)\n",
    "y_new = np.reshape(y, (-1,1))\n",
    "p = np.arange(1,51)\n",
    "y_final = y_new ** p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
